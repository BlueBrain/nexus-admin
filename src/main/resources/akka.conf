akka {

  http {
    host-connection-pool {
      max-connections = 16
      max-connections = ${?AKKA_HTTP_MAX_CONNECTIONS}
      max-open-requests = 64
      max-open-requests = ${?AKKA_HTTP_MAX_OPEN_REQUESTS}
    }
    sse {
      # The maximum size for parsing server-sent events (96KiB).
      max-event-size = 98304
      max-event-size = ${?AKKA_HTTP_SSE_MAX_EVENT_SIZE}

      # The maximum size for parsing lines of a server-sent event (48KiB).
      max-line-size = 49152
      max-line-size = ${?AKKA_HTTP_SSE_MAX_LINE_SIZE}
    }
  }

  loggers = ["akka.event.slf4j.Slf4jLogger"]
  logging-filter = "akka.event.slf4j.Slf4jLoggingFilter"
  log-dead-letters = off
  loglevel = INFO
  loglevel = ${?AKKA_LOG_LEVEL}

  extensions += "akka.cluster.ddata.DistributedData"

  actor {

    provider = "akka.cluster.ClusterActorRefProvider"

    enable-additional-serialization-bindings = on

    allow-java-serialization = off

    serializers {
      circeEvent = "ch.epfl.bluebrain.nexus.admin.persistence.EventSerializer"
      kryo = "io.altoo.akka.serialization.kryo.KryoSerializer"
    }

    serialization-bindings {
      "ch.epfl.bluebrain.nexus.admin.organizations.OrganizationEvent" = circeEvent
      "ch.epfl.bluebrain.nexus.admin.projects.ProjectEvent"           = circeEvent

      "ch.epfl.bluebrain.nexus.sourcing.akka.Msg"                                       = kryo
      "ch.epfl.bluebrain.nexus.sourcing.projections.StreamSupervisor$Start"             = kryo
      "ch.epfl.bluebrain.nexus.sourcing.projections.StreamSupervisor$Stop$"             = kryo
      "ch.epfl.bluebrain.nexus.sourcing.projections.StreamSupervisor$FetchLatestState$" = kryo
      "ch.epfl.bluebrain.nexus.sourcing.projections.StreamSupervisor$LatestState"       = kryo

      "java.util.UUID"                                = kryo
      "ch.epfl.bluebrain.nexus.admin.types.ResourceF" = kryo

      "scala.runtime.BoxedUnit" = kryo
    }
  }

  cluster {
    min-nr-of-members = 1
    min-nr-of-members = ${?CLUSTER_MIN_NR_OF_MEMBERS}
    sharding.state-store-mode = ddata
    downing-provider-class = "ch.epfl.bluebrain.nexus.commons.downing.KeepOldestAkkaDowningProvider"
    downing-provider-class = ${?DOWNING_PROVIDER_CLASS}
  }

  remote {
    startup-timeout = 30 s
    artery {
      transport = tcp
      canonical.hostname = ${app.instance.interface}
      canonical.hostname = ${?REMOTING_INTERFACE}
      canonical.hostname = ${?override.remoting.interface}
      canonical.port = 2552
      canonical.port = ${?REMOTING_PORT}
      canonical.port = ${?override.remoting.port}
      advanced {
        maximum-frame-size = ${?REMOTING_MAXIMUM_FRAME_SIZE}
      }
    }
  }

  persistence {
    journal.plugin = ${app.persistence.journal-plugin}
    snapshot-store.plugin = ${app.persistence.snapshot-store-plugin}
  }

  kafka.producer {
    parallelism = 100
    batch.size = 100
    close-timeout = 60s
    use-dispatcher = "akka.kafka.default-dispatcher"

    kafka-clients {
      bootstrap.servers = "localhost:9092"
      bootstrap.servers = ${?KAFKA_BOOTSTRAP_SERVERS}
    }
  }
}

akka-kryo-serialization {
  idstrategy = "automatic"

  # Log implicitly registered classes. Useful, if you want to know all classes which are serialized.
  implicit-registration-logging = true

  # Set compression
  post-serialization-transformations = "lz4"
  post-serialization-transformations = ${?KRYO_COMPRESSION}
}